{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used for feature selection using wrapper based feature selection mechanism where SVM with rbf kernel is used as a classifier. Feature selection and backward elimination both techquies are used. top_feature variable is used for selecting the different number of opcodes. It finds out that top 116 features help better in classification. Following is the code where we get features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and initializing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "path_tr='nn_500_data_to_tra.csv'\n",
    "path_futr='nn_500_data_to_traFull.csv'\n",
    "path_te='nn_500_data_to_test.csv'\n",
    "path_val='nn_500_data_to_val.csv'\n",
    "top_feature=116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.genfromtxt(path_tr, delimiter=\",\", dtype=str)\n",
    "val = np.genfromtxt(path_val, delimiter=\",\", dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data  = train[1:,0:top_feature]\n",
    "x_label = train[1:,-1]\n",
    "x_data=x_data.astype(np.float)\n",
    "x_label=x_label.astype(np.int)\n",
    "# Binarize the output\n",
    "x_label = label_binarize(x_label, classes=[1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "y_data  = val[1:,0:top_feature]\n",
    "y_data=y_data.astype(np.float)\n",
    "y_label = val[1:,-1]\n",
    "y_label=y_label.astype(np.int)\n",
    "woby=y_label\n",
    "# Binarize the output\n",
    "y_label = label_binarize(y_label, classes=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying custom grid search. optimize c and g values store in opt_c,opt_g respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[0.01,0.1,1,10,100]\n",
    "g=[0.01,0.1,1,10,100]\n",
    "loss=100\n",
    "opt_c=0\n",
    "opt_g=0\n",
    "for i in c:\n",
    "    for j in g:    \n",
    "        clf = OneVsRestClassifier(svm.SVC(kernel='rbf',C=i,gamma=j, probability=True))\n",
    "        clf_f = clf.fit(x_data, x_label)\n",
    "        y_score=clf_f.decision_function(y_data)\n",
    "        y_predict_prob=clf_f.predict_proba(y_data)\n",
    "        y_predict=clf_f.predict(y_data)\n",
    "        pre=y_predict.argmax(1)\n",
    "        pre=pre+1\n",
    "        a=log_loss(y_label,y_predict_prob)\n",
    "        if a<loss:\n",
    "            opt_c=i\n",
    "            opt_g=j\n",
    "            loss=a\n",
    "        print(confusion_matrix(woby,pre))\n",
    "        print('log loss: ',a,'  C: ',i,'  G: ',j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from train full data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.genfromtxt(path_futr, delimiter=\",\", dtype=str)\n",
    "test = np.genfromtxt(path_te, delimiter=\",\", dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data  = train[1:,0:top_feature]\n",
    "x_label = train[1:,-1]\n",
    "x_data=x_data.astype(np.float)\n",
    "x_label=x_label.astype(np.int)\n",
    "# Binarize the output\n",
    "x_label = label_binarize(x_label, classes=[1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "\n",
    "y_data  = test[1:,0:top_feature]\n",
    "y_data=y_data.astype(np.float)\n",
    "\n",
    "y_label = test[1:,-1]\n",
    "y_label=y_label.astype(np.int)\n",
    "woby=y_label\n",
    "# Binarize the output\n",
    "y_label = label_binarize(y_label, classes=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the classifier(SVM) on optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(svm.SVC(kernel='rbf',C=opt_c,gamma=opt_g, probability=True))\n",
    "clf_f = clf.fit(x_data, x_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log_loss and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score=clf_f.decision_function(y_data)\n",
    "y_predict_prob=clf_f.predict_proba(y_data)\n",
    "y_predict=clf_f.predict(y_data)\n",
    "pre=y_predict.argmax(1)\n",
    "pre=pre+1\n",
    "\n",
    "a=log_loss(y_label,y_predict_prob)\n",
    "\n",
    "print(confusion_matrix(woby,pre)) \n",
    "\n",
    "print('log loss: ',a,'  C: ',opt_c,'  G: ',opt_g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
