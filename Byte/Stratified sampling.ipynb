{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "import csv\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stratified_data takes three parameters, target_file, new_file(name of the file where to store new stratified data) and splitting rate. In Section-1 of the following code data, name and labels are read from CSV (numpy array format) and converted to list for further processing. As samples are in cluster form, so for the purpose of splitting, started index of each group is stored in Section-2. Random but stratified indexes of samples are pick from each group and store in the stratified_sample list variable in Section-3. In Section-4, against each stored index in stratified_sample list data of samples along with their name and labels store in data_to_write list for writing it to the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_data(target_file,new_file,spliting_rate=0.2):\n",
    "\n",
    "#Section-1\n",
    "    trainlabel = numpy.genfromtxt(target_file, delimiter=\",\", dtype=str)\n",
    "    FileName=trainlabel[0:,-2]\n",
    "    dat=trainlabel[0:,0:-2]\n",
    "    dat=dat.astype(numpy.float)\n",
    "    Label=trainlabel[0:, -1]\n",
    "    Label=Label.astype(numpy.int)    \n",
    "    dat=dat.tolist()\n",
    "    FileName = FileName.tolist()\n",
    "    Label=Label.tolist()\n",
    "\n",
    "#Section-2\n",
    "    record=[]\n",
    "    b=[]\n",
    "    count=0\n",
    "    temp=[]\n",
    "    starting_index=0\n",
    "\n",
    "    for i in Label:\n",
    "        if i not in b:\n",
    "            if starting_index!=0:\n",
    "                temp.append(count)\n",
    "                record.append(temp)\n",
    "            #     print(temp)\n",
    "                temp=[]\n",
    "                count=0\n",
    "            b.append(i)\n",
    "            temp.append(i)\n",
    "            temp.append(starting_index)\n",
    "        count+=1\n",
    "        starting_index += 1\n",
    "    temp.append(count)\n",
    "    record.append(temp)\n",
    "    \n",
    "#Section-3\n",
    "    stratified_sample=[]\n",
    "    for i in record:\n",
    "        count=0\n",
    "        temp=[]\n",
    "        while count<=floor(i[2]*spliting_rate):\n",
    "            a=random.randint(i[1],(i[1]+i[2]-1))\n",
    "            if a not in temp:\n",
    "                #      print(a)\n",
    "                count+=1\n",
    "                temp.append(a)\n",
    "        stratified_sample.append(temp)\n",
    "#Section-4\n",
    "    data_to_write=[]\n",
    "    count=0\n",
    "    c=0\n",
    "    for i in stratified_sample:\n",
    "        c+=1\n",
    "        print('Class ',c,' samples = ',len(i))\n",
    "        count+=len(i)\n",
    "        for j in i:\n",
    "            a=dat[j]\n",
    "            a.append(FileName[j].strip('\"'))\n",
    "            a.append(Label[j])\n",
    "            data_to_write.append(a)\n",
    "    print('Total samples ',count)\n",
    "\n",
    "    myFile = open(new_file, 'w', newline='')  \n",
    "    with myFile:  \n",
    "        writer = csv.writer(myFile)\n",
    "        writer.writerows(data_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_validation_split function do the actual work of splitting using the stratified_data function, it takes the name of target CSV and generates two CSV, train and validation without affecting the original CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(data_csv,train_csv,validation_csv,training_data_rate=0.5):\n",
    "    \n",
    "    data_to_write=[]\n",
    "    to_list=[]\n",
    "    \n",
    "    stratified_data(data_csv,train_csv,training_data_rate)\n",
    "    \n",
    "    new_train_data = numpy.genfromtxt(train_csv, delimiter=\",\", dtype=str)\n",
    "    new_whole_data = numpy.genfromtxt(data_csv, delimiter=\",\", dtype=str)\n",
    "    \n",
    "    for i in new_train_data:\n",
    "    \n",
    "        to_list.append(i[-2])\n",
    "    \n",
    "    for i in new_whole_data:\n",
    "        a=i[-2].strip('\"')\n",
    "        if a not in to_list:\n",
    "        \n",
    "            data_to_write.append(i)\n",
    "    myFile = open(validation_csv, 'w', newline='')  \n",
    "    \n",
    "    with myFile:  \n",
    "        writer = csv.writer(myFile)\n",
    "        writer.writerows(data_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo to use train_validation_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples in different classes that store in data_to_traFull according to given rate\n",
      "\n",
      "Class  1  samples =  1150\n",
      "Class  2  samples =  1859\n",
      "Class  3  samples =  2207\n",
      "Class  4  samples =  357\n",
      "Class  5  samples =  32\n",
      "Class  6  samples =  564\n",
      "Class  7  samples =  299\n",
      "Class  8  samples =  922\n",
      "Class  9  samples =  760\n",
      "Total samples  8150\n",
      "No. of samples in different classes that store in data_to_tra according to given rate\n",
      "\n",
      "Class  1  samples =  863\n",
      "Class  2  samples =  1395\n",
      "Class  3  samples =  1656\n",
      "Class  4  samples =  268\n",
      "Class  5  samples =  25\n",
      "Class  6  samples =  424\n",
      "Class  7  samples =  225\n",
      "Class  8  samples =  692\n",
      "Class  9  samples =  571\n",
      "Total samples  6119\n"
     ]
    }
   ],
   "source": [
    "data='data_new.csv'\n",
    "\n",
    "train_full='data_to_traFull.csv'\n",
    "test='data_to_test.csv'\n",
    "train='data_to_tra.csv'\n",
    "valid='data_to_val.csv'\n",
    "\n",
    "#0.75 means 75% data will stores in train_full and 25% will be in test  \n",
    "print('No. of samples in different classes that store in data_to_traFull according to given rate\\n')\n",
    "train_validation_split(data,train_full,test,0.75)\n",
    "print('No. of samples in different classes that store in data_to_tra according to given rate\\n')\n",
    "train_validation_split(train_full,train,valid,0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
